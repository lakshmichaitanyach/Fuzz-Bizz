{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chluc\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6b2794120e41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Based FizzBuzz Function [Software 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz(n):\n",
    "    \n",
    "    # Logic Explanation\n",
    "    if n % 3 == 0 and n % 5 == 0:\n",
    "        return 'FizzBuzz'\n",
    "    elif n % 3 == 0:\n",
    "        return 'Fizz'\n",
    "    elif n % 5 == 0:\n",
    "        return 'Buzz'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Testing Datasets in CSV Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInputCSV(start,end,filename):\n",
    "    \n",
    "    # Why list in Python?\n",
    "    inputData   = []\n",
    "    outputData  = []\n",
    "    \n",
    "    # Why do we need training Data?\n",
    "    for i in range(start,end):\n",
    "        inputData.append(i)\n",
    "        outputData.append(fizzbuzz(i))\n",
    "    \n",
    "    # Why Dataframe?\n",
    "    dataset = {}\n",
    "    dataset[\"input\"]  = inputData\n",
    "    dataset[\"label\"] = outputData\n",
    "    \n",
    "    # Writing to csv\n",
    "    pd.DataFrame(dataset).to_csv(filename)\n",
    "    \n",
    "    print(filename, \"Created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Input and Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(dataset):\n",
    "    \n",
    "    # Why do we have to process?\n",
    "    data   = dataset['input'].values\n",
    "    labels = dataset['label'].values\n",
    "    \n",
    "    processedData  = encodeData(data)\n",
    "    processedLabel = encodeLabel(labels)\n",
    "    \n",
    "    return processedData, processedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encodeData(data):\n",
    "    \n",
    "    processedData = []\n",
    "    \n",
    "    for dataInstance in data:\n",
    "        \n",
    "        # Why do we have number 10?\n",
    "        processedData.append([dataInstance >> d & 1 for d in range(10)])\n",
    "    \n",
    "    return np.array(processedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeLabel(labels):\n",
    "    \n",
    "    processedLabel = []\n",
    "    \n",
    "    for labelInstance in labels:\n",
    "        if(labelInstance == \"FizzBuzz\"):\n",
    "            # Fizzbuzz\n",
    "            processedLabel.append([3])\n",
    "        elif(labelInstance == \"Fizz\"):\n",
    "            # Fizz\n",
    "            processedLabel.append([1])\n",
    "        elif(labelInstance == \"Buzz\"):\n",
    "            # Buzz\n",
    "            processedLabel.append([2])\n",
    "        else:\n",
    "            # Other\n",
    "            processedLabel.append([0])\n",
    "\n",
    "    return np_utils.to_categorical(np.array(processedLabel),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datafiles\n",
    "createInputCSV(101,1001,'training.csv')\n",
    "createInputCSV(1,101,'testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "trainingData = pd.read_csv('training.csv')\n",
    "testingData  = pd.read_csv('testing.csv')\n",
    "\n",
    "# Process Dataset\n",
    "processedTrainingData, processedTrainingLabel = processData(trainingData)\n",
    "processedTestingData, processedTestingLabel   = processData(testingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Placeholder\n",
    "inputTensor  = tf.placeholder(tf.float32, [None, 10])\n",
    "outputTensor = tf.placeholder(tf.float32, [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_NEURONS_LAYER_1 = 100\n",
    "LEARNING_RATE = 0.05\n",
    "\n",
    "# Initializing the weights to Normal Distribution\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev=0.01))\n",
    "\n",
    "# Initializing the input to hidden layer weights\n",
    "input_hidden_weights  = init_weights([10, NUM_HIDDEN_NEURONS_LAYER_1])\n",
    "# Initializing the hidden to output layer weights\n",
    "hidden_output_weights = init_weights([NUM_HIDDEN_NEURONS_LAYER_1, 4])\n",
    "\n",
    "# Computing values at the hidden layer\n",
    "hidden_layer = tf.nn.relu(tf.matmul(inputTensor, input_hidden_weights))\n",
    "# Computing values at the output layer\n",
    "output_layer = tf.matmul(hidden_layer, hidden_output_weights)\n",
    "\n",
    "# Defining Error Function\n",
    "error_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=outputTensor))\n",
    "\n",
    "# Defining Learning Algorithm and Training Parameters\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(error_function)\n",
    "\n",
    "# Prediction Function\n",
    "prediction = tf.argmax(output_layer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_EPOCHS = 5000\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "training_accuracy = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Set Global Variables ?\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(NUM_OF_EPOCHS)):\n",
    "        \n",
    "        #Shuffle the Training Dataset at each epoch\n",
    "        p = np.random.permutation(range(len(processedTrainingData)))\n",
    "        processedTrainingData  = processedTrainingData[p]\n",
    "        processedTrainingLabel = processedTrainingLabel[p]\n",
    "        \n",
    "        # Start batch training\n",
    "        for start in range(0, len(processedTrainingData), BATCH_SIZE):\n",
    "            end = start + BATCH_SIZE\n",
    "            sess.run(training, feed_dict={inputTensor: processedTrainingData[start:end], \n",
    "                                          outputTensor: processedTrainingLabel[start:end]})\n",
    "        # Training accuracy for an epoch\n",
    "        training_accuracy.append(np.mean(np.argmax(processedTrainingLabel, axis=1) ==\n",
    "                             sess.run(prediction, feed_dict={inputTensor: processedTrainingData,\n",
    "                                                             outputTensor: processedTrainingLabel})))\n",
    "    # Testing\n",
    "    predictedTestLabel = sess.run(prediction, feed_dict={inputTensor: processedTestingData})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['acc'] = training_accuracy\n",
    "df.plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeLabel(encodedLabel):\n",
    "    if encodedLabel == 0:\n",
    "        return \"Other\"\n",
    "    elif encodedLabel == 1:\n",
    "        return \"Fizz\"\n",
    "    elif encodedLabel == 2:\n",
    "        return \"Buzz\"\n",
    "    elif encodedLabel == 3:\n",
    "        return \"FizzBuzz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model [Software 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong   = 0\n",
    "right   = 0\n",
    "\n",
    "predictedTestLabelList = []\n",
    "\"\"\n",
    "for i,j in zip(processedTestingLabel,predictedTestLabel):\n",
    "    predictedTestLabelList.append(decodeLabel(j))\n",
    "    \n",
    "    if np.argmax(i) == j:\n",
    "        right = right + 1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "\n",
    "print(\"Errors: \" + str(wrong), \" Correct :\" + str(right))\n",
    "\n",
    "print(\"Testing Accuracy: \" + str(right/(right+wrong)*100))\n",
    "\n",
    "# Please input your UBID and personNumber \n",
    "testDataInput = testingData['input'].tolist()\n",
    "testDataLabel = testingData['label'].tolist()\n",
    "\n",
    "testDataInput.insert(0, \"UBID\")\n",
    "testDataLabel.insert(0, \"XXXXXXXX\")\n",
    "\n",
    "testDataInput.insert(1, \"personNumber\")\n",
    "testDataLabel.insert(1, \"XXXXXXXX\")\n",
    "\n",
    "predictedTestLabelList.insert(0, \"\")\n",
    "predictedTestLabelList.insert(1, \"\")\n",
    "\n",
    "output = {}\n",
    "output[\"input\"] = testDataInput\n",
    "output[\"label\"] = testDataLabel\n",
    "\n",
    "output[\"predicted_label\"] = predictedTestLabelList\n",
    "\n",
    "opdf = pd.DataFrame(output)\n",
    "opdf.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
